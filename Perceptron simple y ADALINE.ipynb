{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón simple\n",
    "\n",
    "Clase del perceptrón simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class PerceptronSimple(object):\n",
    "    def __init__(self,n_inputs,pesos=[],bias=0):\n",
    "        self.bias = bias\n",
    "        if len(pesos) == 0:\n",
    "            self.pesos = np.random.random(n_inputs)\n",
    "            self.pesos -= 0.5\n",
    "        elif len(pesos) == n_inputs:\n",
    "            self.pesos = pesos\n",
    "        else:\n",
    "            raise Exception()\n",
    "            \n",
    "    def predict(self,data):\n",
    "        output = np.zeros(data.shape[0])\n",
    "        for i,sample in enumerate(data):\n",
    "            # Sumatorio de productos\n",
    "            out = 0\n",
    "            for j,inp in enumerate(sample):\n",
    "                out += inp*self.pesos[j]\n",
    "            out += self.bias\n",
    "            # Funcion de activacion\n",
    "            output[i] = np.sign(out)\n",
    "        return output\n",
    "    \n",
    "    def get_params(self):\n",
    "        return (self.pesos,self.bias)\n",
    "    \n",
    "    def train(self,x,y):\n",
    "        fail = True\n",
    "        while fail:\n",
    "            print(self.get_params())\n",
    "            fail = False\n",
    "            # EPOCA\n",
    "            output = self.predict(x)\n",
    "            for i in range(x.shape[0]):\n",
    "                if abs(output[i] - y[i,0]) > 0.1:\n",
    "                    for j in range(len(self.pesos)):\n",
    "                        w = y[i,0]*x[i,j]\n",
    "                        self.pesos[j] += w\n",
    "                        self.bias += y[i,0]\n",
    "                    fail = True\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "original = np.array([\n",
    "    [1,1,1],\n",
    "    [2,1,1],\n",
    "    [2,2,1],\n",
    "    [1,3,1],\n",
    "    [-1,1,-1],\n",
    "    [0,2,-1],\n",
    "    [-1,3,-1]\n",
    "])\n",
    "data = np.zeros(original.shape)\n",
    "data[:,[0,1]] = MinMaxScaler().fit(original[:,[0,1]]).transform(original[:,[0,1]])\n",
    "data[:,[2]] = original[:,[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PerceptronSimple(2,[0.75,1],-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.75, 1], -3)\n",
      "([4.083333333333333, 2.5], 5.0)\n",
      "([3.7499999999999996, 1.0], -1.0)\n",
      "([3.416666666666666, -0.5], -5.0)\n",
      "([6.75, 1.0], 3.0)\n",
      "([6.416666666666667, -0.5], -3.0)\n"
     ]
    }
   ],
   "source": [
    "p.train(data[:,[0,1]],data[:,[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.predict(data[:,[0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline\n",
    "[Dataset computer hardware](http://archive.ics.uci.edu/ml/datasets/Computer+Hardware)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"machine.data\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = MinMaxScaler().fit(df[[2,3,4,5,6,7,8]]).transform(df[[2,3,4,5,6,7,8]])\n",
    "\n",
    "Y = MinMaxScaler().fit(df[9].reshape(-1,1)).transform(df[9].reshape(-1,1))\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaline = MLPRegressor(hidden_layer_sizes=[],solver=\"sgd\",alpha=0.1,batch_size=1,max_iter=5000,momentum=0,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.40959164\n",
      "Iteration 2, loss = 0.32092856\n",
      "Iteration 3, loss = 0.25509900\n",
      "Iteration 4, loss = 0.20605179\n",
      "Iteration 5, loss = 0.16934551\n",
      "Iteration 6, loss = 0.14173643\n",
      "Iteration 7, loss = 0.12081504\n",
      "Iteration 8, loss = 0.10484547\n",
      "Iteration 9, loss = 0.09261041\n",
      "Iteration 10, loss = 0.08309452\n",
      "Iteration 11, loss = 0.07560897\n",
      "Iteration 12, loss = 0.06963486\n",
      "Iteration 13, loss = 0.06479030\n",
      "Iteration 14, loss = 0.06077104\n",
      "Iteration 15, loss = 0.05739725\n",
      "Iteration 16, loss = 0.05450392\n",
      "Iteration 17, loss = 0.05197769\n",
      "Iteration 18, loss = 0.04974558\n",
      "Iteration 19, loss = 0.04773721\n",
      "Iteration 20, loss = 0.04589844\n",
      "Iteration 21, loss = 0.04420677\n",
      "Iteration 22, loss = 0.04263544\n",
      "Iteration 23, loss = 0.04115828\n",
      "Iteration 24, loss = 0.03976351\n",
      "Iteration 25, loss = 0.03844218\n",
      "Iteration 26, loss = 0.03718480\n",
      "Iteration 27, loss = 0.03598284\n",
      "Iteration 28, loss = 0.03483182\n",
      "Iteration 29, loss = 0.03372897\n",
      "Iteration 30, loss = 0.03266875\n",
      "Iteration 31, loss = 0.03164815\n",
      "Iteration 32, loss = 0.03066509\n",
      "Iteration 33, loss = 0.02971802\n",
      "Iteration 34, loss = 0.02880534\n",
      "Iteration 35, loss = 0.02792506\n",
      "Iteration 36, loss = 0.02707711\n",
      "Iteration 37, loss = 0.02625805\n",
      "Iteration 38, loss = 0.02546746\n",
      "Iteration 39, loss = 0.02470394\n",
      "Iteration 40, loss = 0.02396623\n",
      "Iteration 41, loss = 0.02325579\n",
      "Iteration 42, loss = 0.02256849\n",
      "Iteration 43, loss = 0.02190529\n",
      "Iteration 44, loss = 0.02126368\n",
      "Iteration 45, loss = 0.02064445\n",
      "Iteration 46, loss = 0.02004615\n",
      "Iteration 47, loss = 0.01946827\n",
      "Iteration 48, loss = 0.01890948\n",
      "Iteration 49, loss = 0.01836972\n",
      "Iteration 50, loss = 0.01784887\n",
      "Iteration 51, loss = 0.01734506\n",
      "Iteration 52, loss = 0.01685809\n",
      "Iteration 53, loss = 0.01638767\n",
      "Iteration 54, loss = 0.01593287\n",
      "Iteration 55, loss = 0.01549297\n",
      "Iteration 56, loss = 0.01506825\n",
      "Iteration 57, loss = 0.01465755\n",
      "Iteration 58, loss = 0.01426038\n",
      "Iteration 59, loss = 0.01387673\n",
      "Iteration 60, loss = 0.01350576\n",
      "Iteration 61, loss = 0.01314697\n",
      "Iteration 62, loss = 0.01280025\n",
      "Iteration 63, loss = 0.01246513\n",
      "Iteration 64, loss = 0.01214091\n",
      "Iteration 65, loss = 0.01182747\n",
      "Iteration 66, loss = 0.01152435\n",
      "Iteration 67, loss = 0.01123118\n",
      "Iteration 68, loss = 0.01094748\n",
      "Iteration 69, loss = 0.01067363\n",
      "Iteration 70, loss = 0.01040817\n",
      "Iteration 71, loss = 0.01015205\n",
      "Iteration 72, loss = 0.00990410\n",
      "Iteration 73, loss = 0.00966419\n",
      "Iteration 74, loss = 0.00943178\n",
      "Iteration 75, loss = 0.00920728\n",
      "Iteration 76, loss = 0.00898999\n",
      "Iteration 77, loss = 0.00878010\n",
      "Iteration 78, loss = 0.00857677\n",
      "Iteration 79, loss = 0.00838005\n",
      "Iteration 80, loss = 0.00818974\n",
      "Iteration 81, loss = 0.00800555\n",
      "Iteration 82, loss = 0.00782730\n",
      "Iteration 83, loss = 0.00765479\n",
      "Iteration 84, loss = 0.00748788\n",
      "Iteration 85, loss = 0.00732643\n",
      "Iteration 86, loss = 0.00717026\n",
      "Iteration 87, loss = 0.00701903\n",
      "Iteration 88, loss = 0.00687252\n",
      "Iteration 89, loss = 0.00673087\n",
      "Iteration 90, loss = 0.00659384\n",
      "Iteration 91, loss = 0.00646103\n",
      "Iteration 92, loss = 0.00633269\n",
      "Iteration 93, loss = 0.00620830\n",
      "Iteration 94, loss = 0.00608788\n",
      "Iteration 95, loss = 0.00597136\n",
      "Iteration 96, loss = 0.00585837\n",
      "Iteration 97, loss = 0.00574928\n",
      "Iteration 98, loss = 0.00564351\n",
      "Iteration 99, loss = 0.00554123\n",
      "Iteration 100, loss = 0.00544210\n",
      "Iteration 101, loss = 0.00534615\n",
      "Iteration 102, loss = 0.00525309\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.1, batch_size=1, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=[], learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=5000, momentum=0,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaline.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = adaline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_matrix = np.abs(y_predict - y_test[:,0]) < 0.1\n",
    "success = np.sum(ok_matrix)/ok_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto: 0.855072\n",
      "Tasa de error: 0.144928\n"
     ]
    }
   ],
   "source": [
    "print(\"Tasa de acierto: %f\" % success)\n",
    "print(\"Tasa de error: %f\" % (1-success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
