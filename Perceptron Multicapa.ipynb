{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón Multicapa\n",
    "\n",
    "## Computer Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"machine.data\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "X = MinMaxScaler().fit(df[[2,3,4,5,6,7,8]]).transform(df[[2,3,4,5,6,7,8]])\n",
    "#Y = MinMaxScaler().fit_transform(df[[9]])\n",
    "Y = df[[9]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.33,random_state=42)\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos 29\n",
      "Tasa acierto 0.420290\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train,y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "\n",
    "\n",
    "aciertos = np.sum(np.abs(y_predict - y_test) < 0.15*y_test)\n",
    "print(\"Aciertos %d\" % aciertos)\n",
    "print(\"Tasa acierto %f\" % (aciertos/y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADALINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aciertos 9\n",
      "Tasa acierto 0.130435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "reg = MLPRegressor(hidden_layer_sizes=[],solver=\"sgd\",alpha=0.1,batch_size=1,max_iter=5000,momentum=0,activation=\"identity\")\n",
    "reg.fit(x_train,y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "table = np.abs(y_predict - y_test) < 0.15*y_test\n",
    "aciertos = np.sum(table)\n",
    "print(\"Aciertos %d\" % aciertos)\n",
    "tasa = aciertos / y_test.shape[0]\n",
    "print(\"Tasa acierto %f\" % tasa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4181.35068883\n",
      "Iteration 2, loss = 804.57036059\n",
      "Iteration 3, loss = 533.57169044\n",
      "Iteration 4, loss = 600.44910794\n",
      "Iteration 5, loss = 525.26333190\n",
      "Iteration 6, loss = 627.23297135\n",
      "Iteration 7, loss = 580.33225846\n",
      "Iteration 8, loss = 504.64431334\n",
      "Iteration 9, loss = 520.31682696\n",
      "Iteration 10, loss = 483.13485814\n",
      "Iteration 11, loss = 564.47808706\n",
      "Iteration 12, loss = 456.75146237\n",
      "Iteration 13, loss = 506.98598905\n",
      "Iteration 14, loss = 470.22960497\n",
      "Iteration 15, loss = 609.31741247\n",
      "Iteration 16, loss = 476.65775864\n",
      "Iteration 17, loss = 508.51183801\n",
      "Iteration 18, loss = 510.71285060\n",
      "Iteration 19, loss = 479.11361510\n",
      "Iteration 20, loss = 575.36517460\n",
      "Iteration 21, loss = 554.32712928\n",
      "Iteration 22, loss = 456.11765346\n",
      "Iteration 23, loss = 494.07399593\n",
      "Iteration 24, loss = 579.50401898\n",
      "Iteration 25, loss = 485.93976066\n",
      "Iteration 26, loss = 573.59072115\n",
      "Iteration 27, loss = 561.84243348\n",
      "Iteration 28, loss = 666.79635090\n",
      "Iteration 29, loss = 455.31575492\n",
      "Iteration 30, loss = 642.99984788\n",
      "Iteration 31, loss = 592.96677833\n",
      "Iteration 32, loss = 544.62864296\n",
      "Iteration 33, loss = 499.34106807\n",
      "Iteration 34, loss = 518.02726806\n",
      "Iteration 35, loss = 424.63356713\n",
      "Iteration 36, loss = 572.87819316\n",
      "Iteration 37, loss = 434.17923142\n",
      "Iteration 38, loss = 614.74181673\n",
      "Iteration 39, loss = 717.67647027\n",
      "Iteration 40, loss = 595.02568137\n",
      "Iteration 41, loss = 585.23234900\n",
      "Iteration 42, loss = 523.58550889\n",
      "Iteration 43, loss = 387.26992478\n",
      "Iteration 44, loss = 452.21252345\n",
      "Iteration 45, loss = 555.77515128\n",
      "Iteration 46, loss = 497.15288071\n",
      "Iteration 47, loss = 541.70337487\n",
      "Iteration 48, loss = 386.05107217\n",
      "Iteration 49, loss = 475.72270874\n",
      "Iteration 50, loss = 581.67659225\n",
      "Iteration 51, loss = 459.74911639\n",
      "Iteration 52, loss = 391.07565790\n",
      "Iteration 53, loss = 638.50153230\n",
      "Iteration 54, loss = 520.76204511\n",
      "Iteration 55, loss = 546.41525168\n",
      "Iteration 56, loss = 556.08582667\n",
      "Iteration 57, loss = 445.77280090\n",
      "Iteration 58, loss = 452.63154134\n",
      "Iteration 59, loss = 524.31418667\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Aciertos 21\n",
      "Tasa acierto 0.304348\n"
     ]
    }
   ],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(10),solver=\"sgd\",alpha=0.1,batch_size=1,max_iter=5000,verbose=True,activation=\"identity\",momentum=0)\n",
    "reg.fit(x_train,y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "table = np.abs(y_predict - y_test) < 0.15*y_test\n",
    "aciertos = np.sum(table)\n",
    "print(\"Aciertos %d\" % aciertos)\n",
    "tasa = aciertos / y_test.shape[0]\n",
    "print(\"Tasa acierto %f\" % tasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3878.58545303\n",
      "Iteration 2, loss = 747.79859266\n",
      "Iteration 3, loss = 554.61219412\n",
      "Iteration 4, loss = 553.41008396\n",
      "Iteration 5, loss = 441.48072549\n",
      "Iteration 6, loss = 659.49635317\n",
      "Iteration 7, loss = 544.51704098\n",
      "Iteration 8, loss = 607.89957127\n",
      "Iteration 9, loss = 1046.64887193\n",
      "Iteration 10, loss = 554.47994192\n",
      "Iteration 11, loss = 509.58860341\n",
      "Iteration 12, loss = 534.14596795\n",
      "Iteration 13, loss = 568.37691963\n",
      "Iteration 14, loss = 561.66336095\n",
      "Iteration 15, loss = 480.28283503\n",
      "Iteration 16, loss = 461.10581719\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Aciertos 28\n",
      "Tasa acierto 0.405797\n"
     ]
    }
   ],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(15),solver=\"sgd\",alpha=0.1,batch_size=1,max_iter=5000,verbose=True,activation=\"identity\",momentum=0)\n",
    "reg.fit(x_train,y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "table = np.abs(y_predict - y_test) < 0.15*y_test\n",
    "aciertos = np.sum(table)\n",
    "print(\"Aciertos %d\" % aciertos)\n",
    "tasa = aciertos / y_test.shape[0]\n",
    "print(\"Tasa acierto %f\" % tasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4153.27621840\n",
      "Iteration 2, loss = 1235.71074734\n",
      "Iteration 3, loss = 732.05244152\n",
      "Iteration 4, loss = 685.11288733\n",
      "Iteration 5, loss = 601.45178412\n",
      "Iteration 6, loss = 458.87432799\n",
      "Iteration 7, loss = 591.37699431\n",
      "Iteration 8, loss = 553.47942674\n",
      "Iteration 9, loss = 542.65490134\n",
      "Iteration 10, loss = 528.84933774\n",
      "Iteration 11, loss = 553.08615258\n",
      "Iteration 12, loss = 390.81543706\n",
      "Iteration 13, loss = 519.39453655\n",
      "Iteration 14, loss = 536.73142435\n",
      "Iteration 15, loss = 363.56424151\n",
      "Iteration 16, loss = 570.34667441\n",
      "Iteration 17, loss = 506.70555214\n",
      "Iteration 18, loss = 512.60412260\n",
      "Iteration 19, loss = 446.78768912\n",
      "Iteration 20, loss = 543.43532538\n",
      "Iteration 21, loss = 543.21304462\n",
      "Iteration 22, loss = 465.33570272\n",
      "Iteration 23, loss = 535.03596014\n",
      "Iteration 24, loss = 493.40537087\n",
      "Iteration 25, loss = 574.71933675\n",
      "Iteration 26, loss = 487.43111770\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Aciertos 18\n",
      "Tasa acierto 0.260870\n"
     ]
    }
   ],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(20),solver=\"sgd\",batch_size=1,alpha=0.1,max_iter=5000,verbose=True,activation=\"identity\",momentum=0)\n",
    "reg.fit(x_train,y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "table = np.abs(y_predict - y_test) < 0.15*y_test\n",
    "aciertos = np.sum(table)\n",
    "print(\"Aciertos %d\" % aciertos)\n",
    "tasa = aciertos / y_test.shape[0]\n",
    "print(\"Tasa acierto %f\" % tasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3541.87021600\n",
      "Iteration 2, loss = 901.36435854\n",
      "Iteration 3, loss = 677.38131365\n",
      "Iteration 4, loss = 570.81888791\n",
      "Iteration 5, loss = 623.97259709\n",
      "Iteration 6, loss = 552.13463194\n",
      "Iteration 7, loss = 635.72257273\n",
      "Iteration 8, loss = 592.30997469\n",
      "Iteration 9, loss = 582.74307878\n",
      "Iteration 10, loss = 540.14807179\n",
      "Iteration 11, loss = 508.90926717\n",
      "Iteration 12, loss = 481.21165939\n",
      "Iteration 13, loss = 532.73419313\n",
      "Iteration 14, loss = 527.05719199\n",
      "Iteration 15, loss = 546.67066553\n",
      "Iteration 16, loss = 525.40831423\n",
      "Iteration 17, loss = 537.95840729\n",
      "Iteration 18, loss = 499.09678264\n",
      "Iteration 19, loss = 539.00547885\n",
      "Iteration 20, loss = 602.47236542\n",
      "Iteration 21, loss = 557.62597060\n",
      "Iteration 22, loss = 596.59392383\n",
      "Iteration 23, loss = 420.37369227\n",
      "Iteration 24, loss = 503.56712800\n",
      "Iteration 25, loss = 519.45988284\n",
      "Iteration 26, loss = 435.62288528\n",
      "Iteration 27, loss = 623.76349770\n",
      "Iteration 28, loss = 596.83937791\n",
      "Iteration 29, loss = 498.90921842\n",
      "Iteration 30, loss = 568.10772361\n",
      "Iteration 31, loss = 545.81675391\n",
      "Iteration 32, loss = 490.37917096\n",
      "Iteration 33, loss = 577.65590526\n",
      "Iteration 34, loss = 422.80710803\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Aciertos 8\n",
      "Tasa acierto 0.115942\n"
     ]
    }
   ],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(25),solver=\"sgd\",batch_size=1,alpha=0.1,max_iter=5000,verbose=True,activation=\"identity\",momentum=0)\n",
    "reg.fit(x_train,y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "table = np.abs(y_predict - y_test) < 0.15*y_test\n",
    "aciertos = np.sum(table)\n",
    "print(\"Aciertos %d\" % aciertos)\n",
    "tasa = aciertos / y_test.shape[0]\n",
    "print(\"Tasa acierto %f\" % tasa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Regresión lineal|ADALINE|MLP(10)|MLP(15)|MLP(20)|MLP(25)|\n",
    "|----------------|-------|-------|-------|-------|-------|\n",
    "|0.4202|0.1449|0.5072|0.4927|0.2898|0.3333|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wine.data\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[[0]]\n",
    "X = df[[1,2,3,4,5,6,7,8,9,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = MinMaxScaler().fit_transform(X)\n",
    "Y = Y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.9722222222222223\n"
     ]
    }
   ],
   "source": [
    "# Perceptrón Multicapa\n",
    "score = 0\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    reg = MLPClassifier(hidden_layer_sizes=(10),solver=\"sgd\",alpha=0.1,batch_size=1,max_iter=5000,verbose=False,activation=\"identity\",momentum=0)\n",
    "    reg.fit(X[train_index],Y[train_index])\n",
    "    score += reg.score(X[test_index],Y[test_index])\n",
    "print(\"Tasa de aciertos =\",score/10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.9833333333333334\n"
     ]
    }
   ],
   "source": [
    "# Reg Logistica\n",
    "score = 0\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in skf.split(X,Y):\n",
    "    reg = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
    "    reg.fit(X[train_index],Y[train_index])\n",
    "    y_p = reg.predict(X[test_index])\n",
    "    score += accuracy_score(Y[test_index],y_p)\n",
    "print(\"Tasa de aciertos =\", score/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
